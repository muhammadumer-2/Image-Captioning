# Image Captioning with BLIP

This project leverages the BLIP (Bootstrapping Language-Image Pre-training) model to generate captions for uploaded images. Built using Flask, the application allows users to upload images and receive descriptive captions generated by the model.

## Features

- Upload images and receive generated captions.
- User-friendly web interface.
- Utilizes the BLIP model for advanced image captioning.

## Technologies Used

- **Flask**: Web framework for Python.
- **Transformers**: Hugging Face library for NLP and vision models.
- **Pillow**: Image processing library in Python.
- **HTML/CSS**: For building the frontend.

## Installation

1. Clone this repository:

   ```bash
   git clone https://github.com/muhammadumer-2/Image-Captioning.git
   cd Image-Captioning
2. Create a virtual environment:

   ```bash
   python -m venv venv
3. Activate the virtual environment:

   On Windows:
   
    ```bash
    venv\Scripts\activate

   On macOS/Linux:
     
    ```bash
    source venv/bin/activate

4. Install the required dependencies:

   '''bash
   pip install -r requirements.txt

   
